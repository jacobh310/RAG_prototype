{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\.virtualenvs\\RAG_prototype-288XYQjQ\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embed_model_id = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "\n",
    "embed_model = HuggingFaceEmbeddings(\n",
    "    model_name=embed_model_id,\n",
    "    model_kwargs={'device': device},\n",
    "    encode_kwargs={'device': device, 'batch_size': 32}\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 2 doc embeddings, each with a dimensionality of 384.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "docs = [\n",
    "    \"this is one document\",\n",
    "    \"and another document\"\n",
    "]\n",
    "\n",
    "embeddings = embed_model.embed_documents(docs)\n",
    "\n",
    "print(f\"We have {len(embeddings)} doc embeddings, each with \"\n",
    "      f\"a dimensionality of {len(embeddings[0])}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# find .env automagically by walking up directories until it's found\n",
    "dotenv_path = find_dotenv()\n",
    "\n",
    "# load up the entries as environment variables\n",
    "load_dotenv(dotenv_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "\n",
    "pinecone_api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "# configure client\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "spec = ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index_name = 'llama-2-rag-proto'\n",
    "\n",
    "import time\n",
    "\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    # if does not exist, create index\n",
    "    pc.create_index(\n",
    "        index_name,\n",
    "        dimension=len(embeddings[0]),\n",
    "        metric='cosine',\n",
    "        spec=spec\n",
    "    )\n",
    "    # wait for index to be initialized\n",
    "    while not pc.describe_index(index_name).status['ready']:\n",
    "        time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connect to index\n",
    "index = pc.Index(index_name)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 409/409 [00:00<?, ?B/s] \n",
      "Downloading data: 100%|██████████| 14.4M/14.4M [00:00<00:00, 19.3MB/s]\n",
      "Generating train split: 100%|██████████| 4838/4838 [00:00<00:00, 21556.60 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\n",
    "    'jamescalam/llama-2-arxiv-papers-chunked',\n",
    "    split='train'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>chunk-id</th>\n",
       "      <th>chunk</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>source</th>\n",
       "      <th>authors</th>\n",
       "      <th>categories</th>\n",
       "      <th>comment</th>\n",
       "      <th>journal_ref</th>\n",
       "      <th>primary_category</th>\n",
       "      <th>published</th>\n",
       "      <th>updated</th>\n",
       "      <th>references</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1102.0183</td>\n",
       "      <td>0</td>\n",
       "      <td>High-Performance Neural Networks\\nfor Visual O...</td>\n",
       "      <td>1102.0183</td>\n",
       "      <td>High-Performance Neural Networks for Visual Ob...</td>\n",
       "      <td>We present a fast, fully parameterizable GPU i...</td>\n",
       "      <td>http://arxiv.org/pdf/1102.0183</td>\n",
       "      <td>[Dan C. Cireşan, Ueli Meier, Jonathan Masci, L...</td>\n",
       "      <td>[cs.AI, cs.NE]</td>\n",
       "      <td>12 pages, 2 figures, 5 tables</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>20110201</td>\n",
       "      <td>20110201</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1102.0183</td>\n",
       "      <td>1</td>\n",
       "      <td>January 2011\\nAbstract\\nWe present a fast, ful...</td>\n",
       "      <td>1102.0183</td>\n",
       "      <td>High-Performance Neural Networks for Visual Ob...</td>\n",
       "      <td>We present a fast, fully parameterizable GPU i...</td>\n",
       "      <td>http://arxiv.org/pdf/1102.0183</td>\n",
       "      <td>[Dan C. Cireşan, Ueli Meier, Jonathan Masci, L...</td>\n",
       "      <td>[cs.AI, cs.NE]</td>\n",
       "      <td>12 pages, 2 figures, 5 tables</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>20110201</td>\n",
       "      <td>20110201</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1102.0183</td>\n",
       "      <td>2</td>\n",
       "      <td>promising architectures for such tasks. The mo...</td>\n",
       "      <td>1102.0183</td>\n",
       "      <td>High-Performance Neural Networks for Visual Ob...</td>\n",
       "      <td>We present a fast, fully parameterizable GPU i...</td>\n",
       "      <td>http://arxiv.org/pdf/1102.0183</td>\n",
       "      <td>[Dan C. Cireşan, Ueli Meier, Jonathan Masci, L...</td>\n",
       "      <td>[cs.AI, cs.NE]</td>\n",
       "      <td>12 pages, 2 figures, 5 tables</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>20110201</td>\n",
       "      <td>20110201</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1102.0183</td>\n",
       "      <td>3</td>\n",
       "      <td>Mutch and Lowe, 2008), whose \flters are \fxed, ...</td>\n",
       "      <td>1102.0183</td>\n",
       "      <td>High-Performance Neural Networks for Visual Ob...</td>\n",
       "      <td>We present a fast, fully parameterizable GPU i...</td>\n",
       "      <td>http://arxiv.org/pdf/1102.0183</td>\n",
       "      <td>[Dan C. Cireşan, Ueli Meier, Jonathan Masci, L...</td>\n",
       "      <td>[cs.AI, cs.NE]</td>\n",
       "      <td>12 pages, 2 figures, 5 tables</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>20110201</td>\n",
       "      <td>20110201</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1102.0183</td>\n",
       "      <td>4</td>\n",
       "      <td>We evaluate various networks on the handwritte...</td>\n",
       "      <td>1102.0183</td>\n",
       "      <td>High-Performance Neural Networks for Visual Ob...</td>\n",
       "      <td>We present a fast, fully parameterizable GPU i...</td>\n",
       "      <td>http://arxiv.org/pdf/1102.0183</td>\n",
       "      <td>[Dan C. Cireşan, Ueli Meier, Jonathan Masci, L...</td>\n",
       "      <td>[cs.AI, cs.NE]</td>\n",
       "      <td>12 pages, 2 figures, 5 tables</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>20110201</td>\n",
       "      <td>20110201</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         doi chunk-id                                              chunk  \\\n",
       "0  1102.0183        0  High-Performance Neural Networks\\nfor Visual O...   \n",
       "1  1102.0183        1  January 2011\\nAbstract\\nWe present a fast, ful...   \n",
       "2  1102.0183        2  promising architectures for such tasks. The mo...   \n",
       "3  1102.0183        3  Mutch and Lowe, 2008), whose \n",
       "lters are \n",
       "xed, ...   \n",
       "4  1102.0183        4  We evaluate various networks on the handwritte...   \n",
       "\n",
       "          id                                              title  \\\n",
       "0  1102.0183  High-Performance Neural Networks for Visual Ob...   \n",
       "1  1102.0183  High-Performance Neural Networks for Visual Ob...   \n",
       "2  1102.0183  High-Performance Neural Networks for Visual Ob...   \n",
       "3  1102.0183  High-Performance Neural Networks for Visual Ob...   \n",
       "4  1102.0183  High-Performance Neural Networks for Visual Ob...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  We present a fast, fully parameterizable GPU i...   \n",
       "1  We present a fast, fully parameterizable GPU i...   \n",
       "2  We present a fast, fully parameterizable GPU i...   \n",
       "3  We present a fast, fully parameterizable GPU i...   \n",
       "4  We present a fast, fully parameterizable GPU i...   \n",
       "\n",
       "                           source  \\\n",
       "0  http://arxiv.org/pdf/1102.0183   \n",
       "1  http://arxiv.org/pdf/1102.0183   \n",
       "2  http://arxiv.org/pdf/1102.0183   \n",
       "3  http://arxiv.org/pdf/1102.0183   \n",
       "4  http://arxiv.org/pdf/1102.0183   \n",
       "\n",
       "                                             authors      categories  \\\n",
       "0  [Dan C. Cireşan, Ueli Meier, Jonathan Masci, L...  [cs.AI, cs.NE]   \n",
       "1  [Dan C. Cireşan, Ueli Meier, Jonathan Masci, L...  [cs.AI, cs.NE]   \n",
       "2  [Dan C. Cireşan, Ueli Meier, Jonathan Masci, L...  [cs.AI, cs.NE]   \n",
       "3  [Dan C. Cireşan, Ueli Meier, Jonathan Masci, L...  [cs.AI, cs.NE]   \n",
       "4  [Dan C. Cireşan, Ueli Meier, Jonathan Masci, L...  [cs.AI, cs.NE]   \n",
       "\n",
       "                         comment journal_ref primary_category published  \\\n",
       "0  12 pages, 2 figures, 5 tables        None            cs.AI  20110201   \n",
       "1  12 pages, 2 figures, 5 tables        None            cs.AI  20110201   \n",
       "2  12 pages, 2 figures, 5 tables        None            cs.AI  20110201   \n",
       "3  12 pages, 2 figures, 5 tables        None            cs.AI  20110201   \n",
       "4  12 pages, 2 figures, 5 tables        None            cs.AI  20110201   \n",
       "\n",
       "    updated references  \n",
       "0  20110201         []  \n",
       "1  20110201         []  \n",
       "2  20110201         []  \n",
       "3  20110201         []  \n",
       "4  20110201         []  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = data.to_pandas()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "696"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = data.to_pandas()\n",
    "\n",
    "len(data.loc[7,'summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "for i in range(0, len(data), batch_size):\n",
    "    i_end = min(len(data), i+batch_size)\n",
    "    batch = data.iloc[i:i_end]\n",
    "    ids = [f\"{x['doi']}-{x['chunk-id']}\" for i, x in batch.iterrows()]\n",
    "    texts = [x['chunk'] for i, x in batch.iterrows()]\n",
    "    embeds = embed_model.embed_documents(texts)\n",
    "    # get metadata to store in Pinecone\n",
    "    metadata = [\n",
    "        {'text': x['chunk'],\n",
    "         'source': x['source'],\n",
    "         'title': x['title']} for i, x in batch.iterrows()\n",
    "    ]\n",
    "    # add to Pinecone\n",
    "    index.upsert(vectors=zip(ids, embeds, metadata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Parse HTML text file\n",
    "- Read Through the raw data filings\n",
    "- Createa a dataframe, dictionary or json that has the chunks of text from the html filings and associate metadata like company reprot type filing year\n",
    "- chunk id | company | Filing Type | Year | Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import UnstructuredHTMLLoader\n",
    "from langchain_community.document_loaders import BSHTMLLoader\n",
    "import json\n",
    "\n",
    "from unstructured.partition.html import partition_html\n",
    "from unstructured.chunking.title import chunk_by_title\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_file_paths(directory):\n",
    "    file_paths = []\n",
    "    \n",
    "    # Walk the directory tree\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            # Construct the full file path and add it to the list\n",
    "            file_paths.append(os.path.join(root, file))\n",
    "    \n",
    "    return file_paths\n",
    "# Example usage\n",
    "directory_path = \"..\\data\\\\raw\\sec-edgar-filings\"\n",
    "file_paths = get_all_file_paths(directory_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(file_paths[0], 'rb')\n",
    "soup = BeautifulSoup(file, 'html.parser')\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredHTMLLoader(file_paths[0])\n",
    "\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'page_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[43mtext_splitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(texts[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(texts[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\jacob\\.virtualenvs\\RAG_prototype-288XYQjQ\\Lib\\site-packages\\langchain_text_splitters\\base.py:94\u001b[0m, in \u001b[0;36mTextSplitter.split_documents\u001b[1;34m(self, documents)\u001b[0m\n\u001b[0;32m     92\u001b[0m texts, metadatas \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents:\n\u001b[1;32m---> 94\u001b[0m     texts\u001b[38;5;241m.\u001b[39mappend(\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m)\n\u001b[0;32m     95\u001b[0m     metadatas\u001b[38;5;241m.\u001b[39mappend(doc\u001b[38;5;241m.\u001b[39mmetadata)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_documents(texts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'page_content'"
     ]
    }
   ],
   "source": [
    "texts = text_splitter.split_documents([data])\n",
    "print(texts[0])\n",
    "print(texts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_prototype-288XYQjQ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
